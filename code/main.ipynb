{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11159349-2fa2-47c1-89ef-7858e532075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Waiting for vLLM API to be ready...\n",
      "✅ vLLM is ready!\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import time\n",
    "\n",
    "def wait_for_vllm_ready(url=\"http://localhost:8000/v1/models\", timeout=300):\n",
    "    print(\"⏳ Waiting for vLLM API to be ready...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            response = httpx.get(url, timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(\"✅ vLLM is ready!\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\"❌ Timed out waiting for vLLM.\") from e\n",
    "            time.sleep(5)\n",
    "\n",
    "wait_for_vllm_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a222bc-bdf2-40eb-8f0a-0ccded86adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: lsof: command not found\n"
     ]
    }
   ],
   "source": [
    "!lsof -i :8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce1c6e8-fc52-48dd-a79b-06e744ec661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from tqdm.notebook import tqdm\n",
    "from evaluator import evaluate_ner\n",
    "\n",
    "# initial VLLM\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:8000/v1',\n",
    "    api_key='EMPTY', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c47aa5-7d62-4af3-ac1f-322586e353f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define api sturcture\n",
    "def openai_api_predict(model, query):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': query}\n",
    "        ],\n",
    "        stream=False,\n",
    "        max_tokens=512,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def write_json(data, file_path, indent=4):\n",
    "    Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=indent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab7515-8e0f-477c-83cf-dc8ee564ce79",
   "metadata": {},
   "source": [
    "# A Minimal Demo Experiment on NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e586a3c7-f5fc-49ea-aeae-2bcb07d562b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 309 entries.\n"
     ]
    }
   ],
   "source": [
    "# Setting model and path\n",
    "model_name = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "test_name = 'ner'\n",
    "\n",
    "data_path = Path('/scratch/project_2005072/keshu/cascade-camp-hands-on/data')\n",
    "data_file = data_path / 'topres19th/HIPE-prep.json'\n",
    "pred_path = f'output/{model_name}_{test_name}.json'\n",
    "\n",
    "# read data\n",
    "qas = read_json(data_file)\n",
    "print(f\"Loaded {len(qas)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8a0729-4357-4042-b70a-6cfac24aed6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcf02c75c3047c989bd272edce6c61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: {\"LOC\": [\"AUSTRALIA\", \"NEW ZEALAND\", \"MELBOURNE\", \"TASMANIA\", \"LAUNCESTON\", \"HOBART TOWN\"], \"STREET\": [], \"BUILDING\": [\"Morning Light\", \"Prinre of the Seas\", \"Sirocco\", \"Red Jacket\", \"White Jacket\", \"Star of the East\", \"White star\", \"Mermaid\", \"Telegraph Blue Jaci,et\", \"Shalimar\", \"Arabian\"]}\n",
      "⏱ Time: 1.40s\n",
      "\n",
      "Model output: {\"LOC\": [], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.26s\n",
      "\n",
      "Model output: {\"LOC\": [\"New York\", \"London\", \"Leeds\", \"Bristol\", \"Birmingham\", \"Liverpool\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.52s\n",
      "\n",
      "Model output: {\"LOC\": [\"Edinburgh\", \"Invernessshire\", \"Scotland\"], \"STREET\": [], \"BUILDING\": [\"Saughton-Hall Asylum\", \"Holme\"]}\n",
      "⏱ Time: 0.52s\n",
      "\n",
      "Model output: {\"LOC\": [\"Kensal Green Cemetery\", \"London\"], \"STREET\": [\"Harrow-road\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.40s\n",
      "\n",
      "Model output: {\"LOC\": [\"TAUNTON\", \"Bradford\"], \"STREET\": [\"High-street\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.40s\n",
      "\n",
      "Model output: {\"LOC\": [\"WILTSHIRE\", \"SALISBURY\", \"Basingstoke\", \"Wilts\", \"Dorset\"], \"STREET\": [], \"BUILDING\": [\"Salisbury Training School\", \"Critchell House\", \"Stourhead\", \"Critchell House\", \"Stourhead\", \"Ashmore\", \"Bishopstone\", \"Tisbury\"]}\n",
      "⏱ Time: 1.05s\n",
      "\n",
      "Model output: {\"LOC\": [\"HAMPSHIRE\", \"Winchester\", \"Gosport\", \"Longparish\", \"Whitechurch\", \"Andover\", \"Bath\", \"Hants County Hospital\"], \"STREET\": [], \"BUILDING\": [\"Guildhall\"]}\n",
      "⏱ Time: 0.80s\n",
      "\n",
      "Model output: {\"LOC\": [\"WILTSHIRE\", \"Salisbury\", \"Malmesbury\", \"Brembill\", \"West Laviogton\", \"Devizes\"], \"STREET\": [\"King’s Arms Inn\", \"Black Horse Inn\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.72s\n",
      "\n",
      "Model output: {\"LOC\": [\"England\", \"Portugal\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.32s\n",
      "\n",
      "Model output: {\"LOC\": [\"Great Britain\", \"Ireland\", \"London\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.39s\n",
      "\n",
      "Model output: {\"LOC\": [\"Blandford\", \"Blandfoid Forum\", \"Salisbury-street\"], \"STREET\": [], \"BUILDING\": [\"MANSION-HOUSK\", \"Capital and Substantial MANSION-HOUSK\", \"Close of MEADOW or PASTURE\", \"Close of valuable and excellent MEADOW or PASTURE\"]}\n",
      "⏱ Time: 0.93s\n",
      "\n",
      "Model output: {\"LOC\": [\"Beaminster, Dorset\", \"Shaston South Down\", \"Blandford\", \"Slumser Newton\"], \"STREET\": [\"Turnpike Road\"], \"BUILDING\": [\"Green-house\"]}\n",
      "⏱ Time: 0.63s\n",
      "\n",
      "Model output: {\"LOC\": [\"HAMPSHIRE\", \"Winchester\"], \"STREET\": [], \"BUILDING\": [\"Castle of Winchester\"]}\n",
      "⏱ Time: 0.40s\n",
      "\n",
      "Model output: {\"LOC\": [\"Manchester\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.28s\n",
      "\n",
      "Model output: {\"LOC\": [], \"STREET\": [], \"BUILDING\": [\"COLONIES\"]}\n",
      "⏱ Time: 0.27s\n",
      "\n",
      "Model output: {\"LOC\": [\"Weymouth\"], \"STREET\": [], \"BUILDING\": [\"Royal Hotel\", \"Belridge\", \"Brunswick-buildings\", \"Greenhill\", \"Portbend Castle\", \"Brunswick steamer\"]}\n",
      "⏱ Time: 0.66s\n",
      "\n",
      "Model output: {\"LOC\": [\"Cherbourg\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.31s\n",
      "\n",
      "Model output: {\"LOC\": [\"Weyhill\"], \"STREET\": [\"Farnhatn-row\", \"Country-row\", \"melksham market\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.53s\n",
      "\n",
      "Model output: {\"LOC\": [\"WEMOUTH\"], \"STREET\": [], \"BUILDING\": [\"GOLDEN LION INN\", \"ROYAL DORSET\", \"SARACENS HEAD\", \"SUTTON HOUSE\", \"BATH\", \"NEW WHITE HORSE CELLAR\", \"SOUTHAMPTON\"]}\n",
      "⏱ Time: 0.85s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running inference\n",
    "\n",
    "preds = []\n",
    "\n",
    "for qa in tqdm(qas[:20]):  # manage to test a small subset, then clear to run all\n",
    "    text = qa['text']\n",
    "\n",
    "    query = f'''\n",
    "    This is a named entity recognition task, which consists of two steps:\n",
    "    1) First, identify all entity mentions in the text.\n",
    "    2) Then classify each mention into one of the following categories:\n",
    "    [\"LOC\", \"STREET\", \"BUILDING\"].\n",
    "\n",
    "    Given the following text:\n",
    "    {text}\n",
    "\n",
    "    Output format: {{\"LOC\": [...], \"STREET\": [...], \"BUILDING\": [...]}}\n",
    "    Do not provide any explanation.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        start = time.time()\n",
    "        answer = openai_api_predict(model_name, query)\n",
    "        duration = time.time() - start\n",
    "        print(f\"Model output: {answer}\")\n",
    "        print(f\"⏱ Time: {duration:.2f}s\\n\")\n",
    "\n",
    "        parsed = ast.literal_eval(answer)\n",
    "        parsed = json.loads(json.dumps(parsed))  # make sure it returns JSON\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        parsed = {\"LOC\": [], \"STREET\": [], \"BUILDING\": []}\n",
    "\n",
    "    preds.append({\n",
    "        \"text\": text,\n",
    "        \"preds\": parsed\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a649541-006d-4052-8fd6-36efee81928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 20 results to: output/Qwen/Qwen2.5-3B-Instruct_ner.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "write_json(preds, pred_path)\n",
    "print(f\"✅ Saved {len(preds)} results to: {pred_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5044fb71-2882-44e2-9d65-edee1e769821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Per-Type Scores =====\n",
      "BUILDING   | P: 0.175, R: 0.3043, F1: 0.2222, TP: 7, FP: 33, FN: 16\n",
      "LOC        | P: 0.7719, R: 0.3929, F1: 0.5207, TP: 44, FP: 13, FN: 68\n",
      "STREET     | P: 0.25, R: 0.2857, F1: 0.2667, TP: 2, FP: 6, FN: 5\n",
      "\n",
      "===== Overall Scores =====\n",
      "Micro-F1:  {'precision': 0.5048, 'recall': 0.3732, 'f1': 0.4291}\n",
      "Macro-F1:  {'f1': 0.3365}\n",
      "\n",
      "✅ Results saved to output/Qwen/Qwen2.5-3B-Instruct_ner_f1_result.json\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "gt_path = \"/scratch/project_2005072/keshu/cascade-camp-hands-on/data/topres19th/HIPE-prep.json\"\n",
    "output_path = f\"output/{model_name}_{test_name}_f1_result.json\"\n",
    "\n",
    "per_type_scores, overall_scores = evaluate_ner(gt_path, pred_path)\n",
    "result = {\n",
    "    \"per_type\": per_type_scores,\n",
    "    \"overall\": overall_scores\n",
    "}\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a4f91-43ac-406f-b107-0ff9ee1c1f72",
   "metadata": {},
   "source": [
    "# Playground\n",
    "Try out your ideas! They could be but not limited to:\n",
    "1. Try a different prompt for the task.\n",
    "2. Try different models in the same pipeline.\n",
    "3. Try to apply the pipeline to your data.\n",
    "4. Try to apply the pipeline to your task.\n",
    "   \n",
    "Things like 3 and 4 may be limited by the time to establish a valid evaluation script. But you are still encouraged to evaluate the results manually!\n",
    "\n",
    "Let's report the most interesting part you found in your experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c0c425-a39e-4f73-8e8c-605a5c3a2daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 309 entries.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbcc968c39f4699bf9a4624070dff03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: {\n",
      "  \"LOC\": [\"AUSTRALIA\", \"NEW ZEALAND\", \"MELBOURNE\", \"TASMANIA\", \"LAUNCESTON\", \"HOBBART TOWN\", \"LIVERPOOL\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.84s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"DORSET COUNTY CHRONICLE AND SOMERSETSHIRE GAZETTE\"]\n",
      "}\n",
      "⏱ Time: 0.54s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.33s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Edinburgh\", \"Invernessshire\", \"Saughton-Hall Asylum\", \"Scotland\", \"Holme\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"Saughton-Hall Asylum\"]\n",
      "}\n",
      "⏱ Time: 0.71s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Kensal Green Cemetery\", \"Taichung\", \"London\"],\n",
      "  \"STREET\": [\"Harrow-road\"],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.52s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Taunton\", \"Bradford\", \"Taunton and Somerset Hospital\", \"St. Marys\"],\n",
      "  \"STREET\": [\"High-street\"],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.64s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Wiltshire\", \"Salisbury\", \"Basingstoke\", \"Southern Counties\", \"Wilts\", \"Dorset\", \"Churchel Parva\", \"More Critchell\", \"Long Crechel\", \"Critchell House\", \"Stourton Caundle\", \"Dorset\", \"Ashmore\", \"Dorset\", \"Bishopstone\", \"Wilts\", \"Tisbury\", \"Wilts\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"Salisbury Training School\", \"Critchell House\", \"Stourhead\", \"Ashmore\", \"Bishopstone\", \"Tisbury\"]\n",
      "}\n",
      "⏱ Time: 1.74s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Hampshire\", \"Winchester\", \"Gosport\", \"Longparish\", \"Whitechurch\", \"Andover\", \"Bath\", \"Hants County Hospital\", \"Walcot\", \"Longparish\", \"Colonel Hawker\", \"the whole neighbourhood\"],\n",
      "  \"STREET\": [\"Sanitary District\", \"Freeway 1\", \"Walcot Street\", \"Andover Road\"],\n",
      "  \"BUILDING\": [\"Guildhall\", \"Town Hall of Gosport\", \"Hants County Hospital\", \"Cooperage Yard of Longparish\"]\n",
      "}\n",
      "⏱ Time: 1.56s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Malmesbury\", \"Salisbury\", \"Brembill\", \"West Laviogton\", \"Devizes\"],\n",
      "  \"STREET\": [\"King’s Arms Inn\", \"Black Horse Inn\"],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.72s\n",
      "\n",
      "Model output: ```json\n",
      "{\n",
      "  \"LOC\": [],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "```\n",
      "⏱ Time: 0.36s\n",
      "\n",
      "⚠️ Error: invalid syntax (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/wuyu1111/29242899/ipykernel_53294/1346984043.py\", line 69, in <module>\n",
      "    parsed = ast.literal_eval(answer)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.12/ast.py\", line 66, in literal_eval\n",
      "    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<unknown>\", line 1\n",
      "    ```json\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: {\n",
      "  \"LOC\": [],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"Piceewno\"]\n",
      "}\n",
      "⏱ Time: 0.39s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Blandford\", \"Taichung\", \"Blandfoid Forum\", \"Salisbury-street\"],\n",
      "  \"STREET\": [\"Freeway 1\", \"Salisbury-street\"],\n",
      "  \"BUILDING\": [\"Lihpao Land\", \"Taichung City Hall\", \"Mansion-Housk\", \"Mansion\", \"Close of Blandfoid Forum\", \"Three Cottages\", \"Stable\", \"Close of valuable and excellent Meadow or Pasture\"]\n",
      "}\n",
      "⏱ Time: 1.37s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Beaminster\", \"Dorset\", \"Ulandfotd\", \"Sturminster Newton\", \"Shaston South Down\"],\n",
      "  \"STREET\": [\"Turnpike Road\"],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.71s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Castle of Winchester\", \"Hamshire\", \"Portsmouth\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.46s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"Maidstone\", \"Manchester\", \"Taichung\", \"Windsor Castle\"]\n",
      "}\n",
      "⏱ Time: 0.53s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Mauritius\", \"Taichung\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.42s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Weymouth\", \"Portsmouth\", \"Flymoile\", \"Flymoilhto Portsmouth\", \"Portbnd Castle\", \"the English Channel\", \"Portland\", \"the island of Portland\", \"the English Channel\", \"the town\", \"the country\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"Royal Hotel\", \"Royal Terrace\", \"Belridere\", \"Marine Villar\", \"Brunswick-buildings\", \"Brunswick steamer\", \"Family residence\"]\n",
      "}\n",
      "⏱ Time: 1.40s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Cherbourg\", \"Yarborough\", \"Thomas\", \"Pelham\", \"Thomas\", \"Poole\", \"Urquhart\", \"Hamilton\"],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": []\n",
      "}\n",
      "⏱ Time: 0.71s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [],\n",
      "  \"STREET\": [],\n",
      "  \"BUILDING\": [\"Mop Fair\", \"Taichung City Hall\", \"Farnhatn-row\", \"Country-row\", \"Country Hops\", \"Andover fair\", \"Melksham market\", \"Reef Its\", \"Silk Trade\"]\n",
      "}\n",
      "⏱ Time: 0.94s\n",
      "\n",
      "Model output: {\n",
      "  \"LOC\": [\"Weymouth\", \"London\", \"Bristol\", \"Southampton\", \"Bath\", \"Guernsey\", \"Jersey\", \"Bath\", \"Bristol\"],\n",
      "  \"STREET\": [\"Hatchets New White Horse Cellar\"],\n",
      "  \"BUILDING\": [\"ROYAL DORSET\", \"New White Horse Cellar\", \"Saracens Head\", \"Ludgate Hill\", \"SOUTHAMPTON\", \"BATH\"]\n",
      "}\n",
      "⏱ Time: 1.31s\n",
      "\n",
      "✅ Saved 20 results to: output/Qwen/Qwen2.5-3B-Instruct_ner_new_prompt.json\n",
      "\n",
      "===== Per-Type Scores =====\n",
      "BUILDING   | P: 0.1915, R: 0.3913, F1: 0.2571, TP: 9, FP: 38, FN: 14\n",
      "LOC        | P: 0.4828, R: 0.375, F1: 0.4221, TP: 42, FP: 45, FN: 70\n",
      "STREET     | P: 0.25, R: 0.4286, F1: 0.3158, TP: 3, FP: 9, FN: 4\n",
      "\n",
      "===== Overall Scores =====\n",
      "Micro-F1:  {'precision': 0.3699, 'recall': 0.3803, 'f1': 0.375}\n",
      "Macro-F1:  {'f1': 0.3317}\n",
      "\n",
      "✅ Results saved to output/Qwen/Qwen2.5-3B-Instruct_ner_new_prompt_f1_result.json\n"
     ]
    }
   ],
   "source": [
    "# Setting model and path\n",
    "model_name = 'Qwen/Qwen2.5-3B-Instruct' # You may change the model and also the one run by vllm. Refer to https://docs.vllm.ai/en/v0.9.2/models/supported_models.html#list-of-text-only-language-models\n",
    "test_name = 'ner_new_prompt' # Edit the test name\n",
    "\n",
    "data_path = Path('/scratch/project_2005072/keshu/cascade-camp-hands-on/data') # You may change the data file path\n",
    "data_file = data_path / 'topres19th/HIPE-prep.json'\n",
    "pred_path = f'output/{model_name}_{test_name}.json' # You could also have your output filename format\n",
    "\n",
    "# read data\n",
    "qas = read_json(data_file) # question and answers\n",
    "print(f\"Loaded {len(qas)} entries.\")\n",
    "\n",
    "\n",
    "# Running inference\n",
    "preds = []\n",
    "\n",
    "for qa in tqdm(qas[:20]):  # manage to test a small subset, then clear to run all\n",
    "    text = qa['text']\n",
    "\n",
    "    # Edit the prompt or even define another task. Here is one example given by Gemini.\n",
    "    query = f\"\"\"\n",
    "    Your task is to perform Named Entity Recognition.\n",
    "    \n",
    "    Extract entities from the text and classify them into one of three categories:\n",
    "    - LOC: Cities, states, countries, or well-known areas.\n",
    "    - STREET: Specific names of roads or streets.\n",
    "    - BUILDING: Specific names of buildings or facilities.\n",
    "    \n",
    "    Provide the output in a single, valid dictionary object format with the keys \"LOC\", \"STREET\", and \"BUILDING\".\n",
    "    If a category has no entities, its value must be an empty list [].\n",
    "    Do not include any additional format words like \"json\". Do not provide any explanations.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Example 1:\n",
    "    Text: The famous Lihpao Land is located in Houli District, not far from San Feng Road.\n",
    "    Output:\n",
    "    {{\n",
    "      \"LOC\": [\"Houli District\"],\n",
    "      \"STREET\": [\"San Feng Road\"],\n",
    "      \"BUILDING\": [\"Lihpao Land\"]\n",
    "    }}\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Example 2:\n",
    "    Text: Many visitors travel along Freeway 1 to get to Taichung City Hall.\n",
    "    Output:\n",
    "    {{\n",
    "      \"LOC\": [\"Taichung\"],\n",
    "      \"STREET\": [\"Freeway 1\"],\n",
    "      \"BUILDING\": [\"Taichung City Hall\"]\n",
    "    }}\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Text to process:\n",
    "    {text}\n",
    "    Output:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        start = time.time()\n",
    "        answer = openai_api_predict(model_name, query)\n",
    "        duration = time.time() - start\n",
    "        print(f\"Model output: {answer}\")\n",
    "        print(f\"⏱ Time: {duration:.2f}s\\n\")\n",
    "\n",
    "        parsed = ast.literal_eval(answer)\n",
    "        parsed = json.loads(json.dumps(parsed))  # make sure it returns JSON\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        parsed = {\"LOC\": [], \"STREET\": [], \"BUILDING\": []}\n",
    "\n",
    "    preds.append({\n",
    "        \"text\": text,\n",
    "        \"preds\": parsed\n",
    "    })\n",
    "\n",
    "\n",
    "# Save results\n",
    "write_json(preds, pred_path)\n",
    "print(f\"✅ Saved {len(preds)} results to: {pred_path}\")\n",
    "\n",
    "# Evaluate\n",
    "gt_path = \"/scratch/project_2005072/keshu/cascade-camp-hands-on/data/topres19th/HIPE-prep.json\" # You may need to change this\n",
    "output_path = f\"output/{model_name}_{test_name}_f1_result.json\" # You may need to change this\n",
    "\n",
    "per_type_scores, overall_scores = evaluate_ner(gt_path, pred_path)\n",
    "result = {\n",
    "    \"per_type\": per_type_scores,\n",
    "    \"overall\": overall_scores\n",
    "}\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804289f-d942-4eb4-b8df-4c010503ad0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
