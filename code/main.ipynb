{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11159349-2fa2-47c1-89ef-7858e532075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Waiting for vLLM API to be ready...\n",
      "✅ vLLM is ready!\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import time\n",
    "\n",
    "def wait_for_vllm_ready(url=\"http://localhost:8000/v1/models\", timeout=300):\n",
    "    print(\"⏳ Waiting for vLLM API to be ready...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            response = httpx.get(url, timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(\"✅ vLLM is ready!\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\"❌ Timed out waiting for vLLM.\") from e\n",
    "            time.sleep(5)\n",
    "\n",
    "wait_for_vllm_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a222bc-bdf2-40eb-8f0a-0ccded86adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: lsof: command not found\n"
     ]
    }
   ],
   "source": [
    "!lsof -i :8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce1c6e8-fc52-48dd-a79b-06e744ec661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# initial VLLM\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:8000/v1',\n",
    "    api_key='EMPTY', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c47aa5-7d62-4af3-ac1f-322586e353f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define api sturcture\n",
    "def openai_api_predict(model, query):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': query}\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def write_json(data, file_path, indent=4):\n",
    "    Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=indent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e586a3c7-f5fc-49ea-aeae-2bcb07d562b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 309 entries.\n"
     ]
    }
   ],
   "source": [
    "# Setting model and path\n",
    "model_name = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "test_name = 'ner'\n",
    "\n",
    "data_path = Path('/scratch/project_2005072/keshu/cascade-camp-hands-on/data')\n",
    "data_file = data_path / 'topres19th/HIPE-prep.json'\n",
    "pred_dir = f'output/{model_name}_{test_name}.json'\n",
    "\n",
    "# read data\n",
    "qas = read_json(data_file)\n",
    "print(f\"Loaded {len(qas)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8a0729-4357-4042-b70a-6cfac24aed6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1309d7d36fb74fdbb8e33a34fe932fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: {\"LOC\": [\"AUSTRALIA\", \"NEW ZEALAND\", \"MELBOURNE\", \"TASMANIA\", \"LAUNCESTON\", \"HOBTART TOWN\"], \"STREET\": [], \"BUILDING\": [\"Morning Light\", \"Prinre of the Seas\", \"Sirocco\", \"Red Jacket\", \"White Jacket\", \"Star of the East\", \"White star\", \"Mermaid\", \"Telegraph Blue Jaci,et\", \"Shalimar\", \"Arabian\"]}\n",
      "⏱ Time: 1.59s\n",
      "\n",
      "Model output: {\"LOC\": [], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.30s\n",
      "\n",
      "Model output: {\"LOC\": [\"New York\", \"London\", \"Leeds\", \"Birmingham\", \"Liverpool\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.54s\n",
      "\n",
      "Model output: {\"LOC\": [\"Edinburgh\", \"Invernessshire\", \"Scotland\"], \"STREET\": [], \"BUILDING\": [\"Saughton-Hall Asylum\"]}\n",
      "⏱ Time: 0.56s\n",
      "\n",
      "Model output: {\"LOC\": [\"Kensal Green Cemetery\", \"London\"], \"STREET\": [\"Harrow-road\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.47s\n",
      "\n",
      "Model output: {\"LOC\": [\"TAUNTON\", \"Bradford\"], \"STREET\": [\"High-street\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.46s\n",
      "\n",
      "Model output: {\"LOC\": [\"WILTSHIRE\", \"SALISBURY\", \"Southern Counties\", \"Wilts\", \"Bath and West of England Society\", \"Churchel Parva\", \"More Critchell\", \"Long Crechel\", \"Dorset\", \"Critchell House\", \"Stourton Caundle\", \"Dorset\", \"Ashmore\", \"Wilts\", \"Tisbury\"], \"STREET\": [], \"BUILDING\": [\"Salisbury Training School\", \"Critchell House\"]}\n",
      "⏱ Time: 1.57s\n",
      "\n",
      "Model output: {\"LOC\": [\"HAMPSHIRE\", \"Winchester\", \"Gosport\", \"Walcot\", \"Bath\", \"Whitechurch\", \"Andover\", \"Longparish\"], \"STREET\": [], \"BUILDING\": [\"Guildhall\", \"Hants County Hospital\", \"barn\", \"coach-house and stables\"]}\n",
      "⏱ Time: 1.05s\n",
      "\n",
      "Model output: {\"LOC\": [\"WILTSHIRE\", \"Salisbury\", \"Malmesbury\", \"Potterne\", \"Brembill\", \"West Laviogton\", \"Devizes\"], \"STREET\": [\"King’s Arms Inn\", \"Black Horse Inn\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.91s\n",
      "\n",
      "Model output: {\"LOC\": [\"FRANCE\", \"PORTUGAL\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.39s\n",
      "\n",
      "Model output: {\"LOC\": [\"Great Britain\", \"Ireland\", \"London\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.44s\n",
      "\n",
      "Model output: {\"LOC\": [\"BLANDFORD\", \"Blandfoid Forum\"], \"STREET\": [\"Salisbury-street\"], \"BUILDING\": [\"MANSION-HOUSK\", \"Capital and Substantial MANSION-HOUSK\", \"THE FEE-SIMPLE and INHERITANCE of all that Capital and Substantial MANSION-HOUSK\", \"Mansion\", \"Close of MEADOW or PASTURE\", \"Close of valuable and excellent MEADOW or PASTURE\"]}\n",
      "⏱ Time: 1.50s\n",
      "\n",
      "Model output: {\"LOC\": [\"Beaminster\", \"Ulandfotd\", \"Sturminster Newton\", \"Shaston South Down\", \"Amesbury\"], \"STREET\": [\"Turnpike Road\"], \"BUILDING\": [\"Green-house\"]}\n",
      "⏱ Time: 0.77s\n",
      "\n",
      "Model output: {\"LOC\": [\"HAMPSHIRE\", \"Winchester\"], \"STREET\": [], \"BUILDING\": [\"Castle of Winchester\"]}\n",
      "⏱ Time: 0.46s\n",
      "\n",
      "Model output: {\"LOC\": [\"Manchester\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.32s\n",
      "\n",
      "Model output: {\"LOC\": [], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.28s\n",
      "\n",
      "Model output: {\n",
      "    \"LOC\": [\"Weymouth\", \"Flymouth\"],\n",
      "    \"STREET\": [],\n",
      "    \"BUILDING\": [\"Royal Hotel\", \"Belridge\", \"Brunswick-buildings\", \"Greenhill\", \"Portbend Castle\", \"Brunswick steamer\"]\n",
      "}\n",
      "⏱ Time: 0.89s\n",
      "\n",
      "Model output: {\"LOC\": [\"Cherbourg\"], \"STREET\": [], \"BUILDING\": []}\n",
      "⏱ Time: 0.36s\n",
      "\n",
      "Model output: {\"LOC\": [\"Weyhill\", \"Country\", \"Jrondale\"], \"STREET\": [\"Farnhatn-row\", \"Country-row\", \"melksham\"], \"BUILDING\": []}\n",
      "⏱ Time: 0.71s\n",
      "\n",
      "Model output: {\"LOC\": [\"Weymouth\"], \"STREET\": [], \"BUILDING\": [\"GOLDEN LION INN\", \"The Stables\", \"New White Horse Cellar\", \"Belle Sauvage\", \"Saracens Head\", \"Royal Dorset\", \"Bath\"]}\n",
      "⏱ Time: 0.93s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running inference\n",
    "\n",
    "preds = []\n",
    "\n",
    "for qa in tqdm(qas[:20]):  # manage to test a small subset, clear to run all\n",
    "    text = qa['text']\n",
    "\n",
    "    query = f'''\n",
    "    This is a named entity recognition task, which consists of two steps:\n",
    "    1) First, identify all entity mentions in the text.\n",
    "    2) Then classify each mention into one of the following categories:\n",
    "    [\"LOC\", \"STREET\", \"BUILDING\"].\n",
    "\n",
    "    Given the following text:\n",
    "    {text}\n",
    "\n",
    "    Output format: {{\"LOC\": [...], \"STREET\": [...], \"BUILDING\": [...]}}\n",
    "    Do not provide any explanation.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        start = time.time()\n",
    "        answer = openai_api_predict(model_name, query)\n",
    "        duration = time.time() - start\n",
    "        print(f\"Model output: {answer}\")\n",
    "        print(f\"⏱ Time: {duration:.2f}s\\n\")\n",
    "\n",
    "        parsed = ast.literal_eval(answer)\n",
    "        parsed = json.loads(json.dumps(parsed))  # make sure it returns JSON\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        parsed = {\"LOC\": [], \"STREET\": [], \"BUILDING\": []}\n",
    "\n",
    "    preds.append({\n",
    "        \"text\": text,\n",
    "        \"preds\": parsed\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a649541-006d-4052-8fd6-36efee81928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 20 results to: output/Qwen/Qwen2.5-3B-Instruct_ner.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "write_json(preds, pred_dir)\n",
    "print(f\"✅ Saved {len(preds)} results to: {pred_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5044fb71-2882-44e2-9d65-edee1e769821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Per-Type Scores =====\n",
      "BUILDING   | P: 0.1951, R: 0.3478, F1: 0.25, TP: 8, FP: 33, FN: 15\n",
      "LOC        | P: 0.7143, R: 0.3571, F1: 0.4762, TP: 40, FP: 16, FN: 72\n",
      "STREET     | P: 0.2, R: 0.2857, F1: 0.2353, TP: 2, FP: 8, FN: 5\n",
      "\n",
      "===== Overall Scores =====\n",
      "Micro-F1:  {'precision': 0.4673, 'recall': 0.3521, 'f1': 0.4016}\n",
      "Macro-F1:  {'f1': 0.3205}\n",
      "\n",
      "✅ Results saved to output/Qwen/Qwen2.5-3B-Instruct_ner_f1_result.json\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "!python evaluator.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
